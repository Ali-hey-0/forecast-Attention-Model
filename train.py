# train.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from dataset import WeatherDataset
from model import Seq2Seq
import matplotlib.pyplot as plt
import os

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
window_size = 168   # 1 Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡
horizon = 72        # 3 Ø±ÙˆØ² Ø¢ÛŒÙ†Ø¯Ù‡
batch_size = 128
num_epochs = 5
hidden_dim = 64
lr = 0.001

# ğŸ“Š Ø¯ÛŒØªØ§Ø³Øª
dataset = WeatherDataset("weather.csv", input_window=window_size, output_window=horizon)
train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ğŸ§  Ù…Ø¯Ù„
model = Seq2Seq(input_dim=1, hidden_dim=hidden_dim, output_window=horizon).to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

# ğŸ“ Ø°Ø®ÛŒØ±Ù‡
os.makedirs("checkpoints", exist_ok=True)

losses = []
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad()
        y_pred = model(x)
        loss = criterion(y_pred, y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    epoch_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}")
    losses.append(epoch_loss)

    # ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù‡Ø± 5 epoch
    if (epoch + 1) % 5 == 0:
        torch.save(model.state_dict(), f"checkpoints/model_epoch{epoch+1}.pth")

# ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Loss
plt.plot(losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss")
plt.grid(True)
plt.show()

# ğŸ§  Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
torch.save(model.state_dict(), "checkpoints/final_attention_model.pth")
